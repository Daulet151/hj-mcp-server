"""
Query Refinement Agent
Modifies existing SQL queries based on user follow-up requests
"""
from typing import Tuple, Optional
from openai import OpenAI
import pandas as pd
from utils.logger import setup_logger

logger = setup_logger(__name__, "INFO")


class QueryRefinementAgent:
    """
    Handles query refinement - modifying existing SQL based on follow-up requests.

    Example:
    Original query: "–°–∫–æ–ª—å–∫–æ –∞—Ç–ª–µ—Ç–æ–≤ –≤—Å—Ç—É–ø–∏–ª–æ –≤ –∫–ª–∞–Ω—ã –≤ —Å–µ–Ω—Ç—è–±—Ä–µ?"
    SQL: SELECT COUNT(*) FROM userclantransaction WHERE month = 'September'

    Follow-up: "–ê –∏–∑ –Ω–∏—Ö —Å–∫–æ–ª—å–∫–æ –∏–º–µ—é—Ç –•–ü?"
    Refined SQL: SELECT COUNT(*) FROM userclantransaction t
                 JOIN subscriptions s ON t.user = s.user
                 WHERE month = 'September' AND s.has_heropass = true
    """

    def __init__(self, api_key: str, schema_docs: dict, model: str = "gpt-4o"):
        """
        Initialize query refinement agent.

        Args:
            api_key: OpenAI API key
            schema_docs: Schema documentation
            model: Model to use
        """
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.schema_docs = schema_docs

        self.system_prompt = """–¢—ã SQL —ç–∫—Å–ø–µ—Ä—Ç –¥–ª—è Hero's Journey, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–µ –∑–∞–ø—Ä–æ—Å–æ–≤.

**–¢–≤–æ—è –∑–∞–¥–∞—á–∞:**
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –ø–æ–ª—É—á–∏–ª –¥–∞–Ω–Ω—ã–µ –ø–æ SQL –∑–∞–ø—Ä–æ—Å—É. –¢–µ–ø–µ—Ä—å –æ–Ω —Ö–æ—á–µ—Ç –£–¢–û–ß–ù–ò–¢–¨/–î–û–ü–û–õ–ù–ò–¢–¨ —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å.
–¢—ã –¥–æ–ª–∂–µ–Ω –ú–û–î–ò–§–ò–¶–ò–†–û–í–ê–¢–¨ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π SQL, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å.

**–í–∞–∂–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞:**

1. **–ù–ï –ø–∏—à–∏ SQL —Å –Ω—É–ª—è!** –ë–µ—Ä–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π SQL –∏ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π –µ–≥–æ.

2. **–°–æ—Ö—Ä–∞–Ω—è–π –ª–æ–≥–∏–∫—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:**
   - –ï—Å–ª–∏ –±—ã–ª COUNT(*) - –æ—Å—Ç–∞–≤—å COUNT(*)
   - –ï—Å–ª–∏ –±—ã–ª–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ - —Å–æ—Ö—Ä–∞–Ω–∏ –µ—ë
   - –ï—Å–ª–∏ –±—ã–ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã - –¥–æ–±–∞–≤—å –Ω–æ–≤—ã–µ, –Ω–µ —É–¥–∞–ª—è–π —Å—Ç–∞—Ä—ã–µ

3. **–¢–∏–ø–∏—á–Ω—ã–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è:**
   - "–∏–∑ –Ω–∏—Ö —Å–∫–æ–ª—å–∫–æ –∏–º–µ—é—Ç –•–ü?" ‚Üí –¥–æ–±–∞–≤—å JOIN —Å –ø–æ–¥–ø–∏—Å–∫–∞–º–∏ + —Ñ–∏–ª—å—Ç—Ä
   - "—Ç–æ–ª—å–∫–æ –º—É–∂—á–∏–Ω—ã" ‚Üí –¥–æ–±–∞–≤—å WHERE sex = 'male'
   - "—Å—Ç–∞—Ä—à–µ 25 –ª–µ—Ç" ‚Üí –¥–æ–±–∞–≤—å WHERE age > 25
   - "—Å –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–æ–π" ‚Üí –¥–æ–±–∞–≤—å JOIN –∏ —Ñ–∏–ª—å—Ç—Ä

4. **–ò—Å–ø–æ–ª—å–∑—É–π schema docs** –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö JOIN'–æ–≤:
   - –ü—Ä–æ–≤–µ—Ä—è–π –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü –∏ –∫–æ–ª–æ–Ω–æ–∫
   - –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ FK —Å–≤—è–∑–∏
   - –ü—Ä–∏–º–µ–Ω—è–π business_rules –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

5. **–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:**
```json
{
  "refined_sql": "MODIFIED SQL HERE",
  "explanation": "–ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –≤ SQL (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º)"
}
```

**–ü—Ä–∏–º–µ—Ä—ã:**

Original SQL:
```sql
SELECT COUNT(*) as count,
       EXTRACT(MONTH FROM created_at) as month
FROM userclantransaction
WHERE created_at >= '2025-09-01' AND created_at < '2025-12-01'
GROUP BY month
```

User refinement: "–∏–∑ –Ω–∏—Ö —Å–∫–æ–ª—å–∫–æ –∏–º–µ—é—Ç –•–ü?"

Refined SQL:
```sql
SELECT COUNT(DISTINCT uct.user) as count,
       EXTRACT(MONTH FROM uct.created_at) as month
FROM userclantransaction uct
JOIN userheropass uhp ON uct.user = uhp.user
WHERE uct.created_at >= '2025-09-01'
  AND uct.created_at < '2025-12-01'
  AND uhp.status = 'active'
  AND (uhp.is_dropped IS NULL OR uhp.is_dropped = false)
GROUP BY month
```

Explanation: "–î–æ–±–∞–≤–∏–ª JOIN —Å —Ç–∞–±–ª–∏—Ü–µ–π userheropass –∏ —Ñ–∏–ª—å—Ç—Ä –Ω–∞ –∞–∫—Ç–∏–≤–Ω—É—é –ø–æ–¥–ø–∏—Å–∫—É."

---

Original SQL:
```sql
SELECT id, firstname, lastname, points
FROM raw.user
WHERE points > 1000
ORDER BY points DESC
LIMIT 10
```

User refinement: "—Ç–æ–ª—å–∫–æ –∂–µ–Ω—â–∏–Ω—ã"

Refined SQL:
```sql
SELECT id, firstname, lastname, points, sex
FROM raw.user
WHERE points > 1000
  AND sex = 'female'
ORDER BY points DESC
LIMIT 10
```

Explanation: "–î–æ–±–∞–≤–∏–ª —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–æ–ª—É (sex = 'female')."

**–°—Ç–∏–ª—å:**
- –ò—Å–ø–æ–ª—å–∑—É–π PostgreSQL —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
- –§–æ—Ä–º–∞—Ç–∏—Ä—É–π SQL —á–∏—Ç–∞–±–µ–ª—å–Ω–æ
- –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π NULL –∑–Ω–∞—á–µ–Ω–∏—è (is_dropped, isdeleted)
- –ò—Å–ø–æ–ª—å–∑—É–π –∞–ª–∏–∞—Å—ã –¥–ª—è —Ç–∞–±–ª–∏—Ü –ø—Ä–∏ JOIN'–∞—Ö"""

    def refine_query(
        self,
        original_sql: str,
        original_user_query: str,
        refinement_request: str,
        sql_generator,
        db_manager
    ) -> Tuple[str, pd.DataFrame, str]:
        """
        Refine existing SQL query based on user's follow-up request.

        Args:
            original_sql: Original SQL query
            original_user_query: Original user question
            refinement_request: User's refinement ("–∏–∑ –Ω–∏—Ö —Å–∫–æ–ª—å–∫–æ –∏–º–µ—é—Ç –•–ü?")
            sql_generator: SQLGenerator instance (for schema context)
            db_manager: DatabaseManager instance (to execute refined SQL)

        Returns:
            Tuple of (analysis, dataframe, refined_sql)
        """
        try:
            logger.info(f"Refining query: '{refinement_request[:100]}'")
            logger.info(f"Original SQL: {original_sql[:200]}...")

            # Build schema context
            schema_context = self._build_schema_context()

            # Create prompt for SQL refinement
            prompt = f"""**–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**
{original_user_query}

**–¢–µ–∫—É—â–∏–π SQL:**
```sql
{original_sql}
```

**–£—Ç–æ—á–Ω–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**
{refinement_request}

**–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –∏ —Å–≤—è–∑–∏:**
{schema_context}

–ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–π SQL —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."""

            # Call GPT to refine SQL
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                response_format={"type": "json_object"}
            )

            # Parse response
            import json
            result = json.loads(response.choices[0].message.content)
            refined_sql = result.get("refined_sql", "")
            explanation = result.get("explanation", "")

            logger.info(f"SQL refined. Explanation: {explanation}")
            logger.info(f"Refined SQL: {refined_sql[:200]}...")

            if not refined_sql:
                raise ValueError("Failed to generate refined SQL")

            # Execute refined SQL
            dataframe = db_manager.execute_query(refined_sql)
            logger.info(f"Refined query returned {len(dataframe)} rows")

            # Generate analysis of refined results
            analysis = self._generate_analysis(
                dataframe=dataframe,
                refined_sql=refined_sql,
                original_query=original_user_query,
                refinement=refinement_request,
                explanation=explanation
            )

            return analysis, dataframe, refined_sql

        except Exception as e:
            logger.error(f"Error in query refinement: {e}")
            raise

    def _build_schema_context(self) -> str:
        """Build schema context from docs."""
        context_parts = []

        if "tables" in self.schema_docs:
            tables_dict = self.schema_docs["tables"]

            # List key tables
            key_tables = ["raw.user", "userheropass", "userclantransaction", "subscription"]

            for table_name in key_tables:
                if table_name in tables_dict or table_name.split('.')[-1] in tables_dict:
                    # Handle both full and short table names
                    table_key = table_name if table_name in tables_dict else table_name.split('.')[-1]
                    table_info = tables_dict.get(table_key, {})

                    description = table_info.get("description", "")
                    context_parts.append(f"- {table_name}: {description}")

                    # Add FK relationships
                    columns = table_info.get("columns", [])
                    fk_cols = [col for col in columns if col.get("role") == "FK"]
                    if fk_cols:
                        fk_info = ", ".join([f"{col['name']} -> {col.get('business_notes', '')}"
                                            for col in fk_cols[:3]])
                        context_parts.append(f"  –°–≤—è–∑–∏: {fk_info}")

        return "\n".join(context_parts) if context_parts else "No schema info available"

    def _generate_analysis(
        self,
        dataframe: pd.DataFrame,
        refined_sql: str,
        original_query: str,
        refinement: str,
        explanation: str
    ) -> str:
        """
        Generate natural language analysis of refined query results.

        Args:
            dataframe: Results from refined query
            refined_sql: The refined SQL
            original_query: Original user question
            refinement: User's refinement request
            explanation: What changed in SQL

        Returns:
            Analysis text
        """
        try:
            # Prepare data summary
            data_summary = self._summarize_dataframe(dataframe)

            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –£–¢–û–ß–ù–Å–ù–ù–û–ì–û –∑–∞–ø—Ä–æ—Å–∞.

**–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:** {original_query}
**–£—Ç–æ—á–Ω–µ–Ω–∏–µ:** {refinement}
**–ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –≤ SQL:** {explanation}

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Ç–æ—á–Ω—ë–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:**
{data_summary}

–î–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π):
1. –û—Ç–≤–µ—Ç –Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å
2. –ö–ª—é—á–µ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
3. –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–∞–∑–±–∏–≤–∫–∞ - –ø–æ–∫–∞–∂–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ

**–°—Ç–∏–ª—å:**
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ç–æ–Ω
- –ù–∞ —Ä—É—Å—Å–∫–æ–º
- –í –∫–æ–Ω—Ü–µ —Å–ø—Ä–æ—Å–∏: "–ñ–µ–ª–∞–µ—Ç–µ —á—Ç–æ–±—ã —è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –¥–ª—è –≤–∞—Å —Ç–∞–±–ª–∏—Ü—É —Å —ç—Ç–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏? üìä"

–ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –≤–µ—Å—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∞–Ω–∞–ª–∏–∑, –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –£–¢–û–ß–ù–ï–ù–ò–ï!"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "–¢—ã AI –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö Hero's Journey."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"Error generating analysis: {e}")
            # Fallback to simple response
            return f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Ç–æ—á–Ω—ë–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {len(dataframe)} –∑–∞–ø–∏—Å–µ–π. –ñ–µ–ª–∞–µ—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É? üìä"

    def _summarize_dataframe(self, df: pd.DataFrame) -> str:
        """Create a text summary of DataFrame for analysis."""
        if df.empty:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

        summary_parts = [
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}",
            f"–ö–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns.tolist())}"
        ]

        # Show first few rows
        preview = df.head(10).to_string(index=False, max_colwidth=50)
        summary_parts.append(f"\n–ü–µ—Ä–≤—ã–µ –∑–∞–ø–∏—Å–∏:\n{preview}")

        # Add basic statistics for numeric columns
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_cols) > 0:
            stats = df[numeric_cols].describe().to_string()
            summary_parts.append(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n{stats}")

        return "\n\n".join(summary_parts)
